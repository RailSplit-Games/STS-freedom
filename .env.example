# LLM Configuration
# Set VITE_LLM_PROVIDER to one of: openai, anthropic, local, none

VITE_LLM_PROVIDER=none

# OpenAI Configuration
VITE_OPENAI_API_KEY=your-openai-api-key-here

# Anthropic Configuration
VITE_ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Local LLM Configuration (Ollama, LM Studio, etc.)
VITE_LOCAL_LLM_URL=http://localhost:11434
